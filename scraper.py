import os
import time
import datetime
import re
import requests
from bs4 import BeautifulSoup

# Selenium ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

# í¬ë¡¬ ë“œë¼ì´ë²„ ìë™ ê´€ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

def run_scraper():
    # ---------------------------------------------------------
    # 1. ê¸°ë³¸ ì„¤ì •
    # ---------------------------------------------------------
    save_dir = "pdf_downloads"
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    today = datetime.datetime.now()
    date_str = today.strftime("%m%d") 
    target_keyword = "í•˜ë£¨ì— í•˜ë‚˜"
    
    print(f"[{today.strftime('%Y-%m-%d')}] '{target_keyword}' ({date_str}) íƒìƒ‰ ì‹œì‘...")

    # ---------------------------------------------------------
    # 2. Selenium ì„¤ì •
    # ---------------------------------------------------------
    chrome_options = Options()
    chrome_options.add_argument("--headless") 
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    # ì°½ í¬ê¸°ë¥¼ í¬ê²Œ ì„¤ì •í•˜ì—¬ ë²„íŠ¼ì´ ì˜ ë³´ì´ë„ë¡ í•¨
    chrome_options.add_argument("--window-size=1920,1080") 
    
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    chrome_options.add_argument(f"user-agent={user_agent}")

    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
    except Exception as e:
        print(f"ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return

    url = "https://www.hanaw.com/main/research/research/RC_000000_M.cmd"
    
    try:
        driver.get(url)
        # bodyê°€ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        time.sleep(2)

        found = False
        max_clicks = 5
        
        for i in range(max_clicks + 1):
            print(f"\n--- í˜ì´ì§€ ìŠ¤ìº” ì¤‘ (í˜„ì¬ ë”ë³´ê¸° í´ë¦­ íšŸìˆ˜: {i}) ---")
            
            # í˜„ì¬ DOM íŒŒì‹±
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            
            # ---------------------------------------------------------
            # 3. ê²Œì‹œê¸€ íƒìƒ‰
            # ---------------------------------------------------------
            for a_tag in soup.find_all('a'):
                text = a_tag.get_text().strip()
                href = a_tag.get('href', '')

                if target_keyword in text and date_str in text:
                    print(f"ğŸ¯ íƒ€ê²Ÿ ë°œê²¬! : {text}")
                    
                    download_link = None
                    if "download.cmd" in href:
                        download_link = href
                        print(" -> ë§í¬ íƒ€ì…: ì§ì ‘ ë‹¤ìš´ë¡œë“œ")
                    else:
                        parent_tr = a_tag.find_parent('tr')
                        if parent_tr:
                            file_btn = parent_tr.find('a', href=re.compile(r'download|file', re.I))
                            if file_btn:
                                download_link = file_btn['href']
                                print(" -> ë§í¬ íƒ€ì…: ì²¨ë¶€íŒŒì¼ ë²„íŠ¼")

                    if not download_link:
                        print(" -> âš ï¸ ë‹¤ìš´ë¡œë“œ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        continue

                    if not download_link.startswith('http'):
                        full_url = "https://www.hanaw.com" + download_link
                    else:
                        full_url = download_link
                    
                    safe_title = text.replace('/', '_').replace('\\', '_').strip()
                    filename = f"{save_dir}/{today.strftime('%Y-%m-%d')}_{safe_title}.pdf"
                    
                    print(f" -> ë‹¤ìš´ë¡œë“œ ì‹œë„: {full_url}")

                    # ì¿ í‚¤ ë™ê¸°í™” í›„ ë‹¤ìš´ë¡œë“œ
                    session = requests.Session()
                    cookies = driver.get_cookies()
                    for cookie in cookies:
                        session.cookies.set(cookie['name'], cookie['value'])
                    
                    headers = {"User-Agent": user_agent}
                    file_res = session.get(full_url, headers=headers)
                    
                    if file_res.status_code == 200:
                        with open(filename, 'wb') as f:
                            f.write(file_res.content)
                        print(f"âœ… ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {filename}")
                        found = True
                        break
                    else:
                        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (HTTP {file_res.status_code})")
            
            if found:
                break
            
            # ---------------------------------------------------------
            # 4. 'ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­ (ê°•ë ¥í•œ ë°©ì‹)
            # ---------------------------------------------------------
            if i < max_clicks:
                try:
                    # 1) ë²„íŠ¼ì´ ì¡´ì¬í•  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 5ì´ˆ)
                    more_btn = WebDriverWait(driver, 5).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, "button.j-moreListBtn"))
                    )
                    
                    # 2) ìŠ¤í¬ë¡¤ì„ ìš”ì†Œì˜ ì¤‘ì•™ìœ¼ë¡œ ì´ë™ (ê°€ë ¤ì§ ë°©ì§€)
                    driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", more_btn)
                    time.sleep(0.5) 
                    
                    # 3) JavaScriptë¡œ ê°•ì œ í´ë¦­ (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
                    driver.execute_script("arguments[0].click();", more_btn)
                    print("â¬‡ï¸ 'ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­ ì™„ë£Œ (JS)")
                    
                    # 4) ë°ì´í„° ë¡œë”© ëŒ€ê¸°
                    time.sleep(3)
                    
                except TimeoutException:
                    print("ğŸš« 'ë”ë³´ê¸°' ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë§ˆì§€ë§‰ í˜ì´ì§€ì¼ ê°€ëŠ¥ì„±)")
                    break
                except Exception as e:
                    print(f"âš ï¸ ë²„íŠ¼ í´ë¦­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    break
            else:
                print("â¹ï¸ ìµœëŒ€ íƒìƒ‰ íšŸìˆ˜ì— ë„ë‹¬í•˜ì—¬ ì¢…ë£Œí•©ë‹ˆë‹¤.")

        if not found:
            print(f"âŒ ê²°ê³¼: ì˜¤ëŠ˜({date_str})ì '{target_keyword}' ë¦¬í¬íŠ¸ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        driver.quit()

if __name__ == "__main__":
    run_scraper()